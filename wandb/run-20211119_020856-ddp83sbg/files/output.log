--------------------------------------------------
torch.Size([1, 3, 250, 250])
torch.Size([1, 250, 250, 3])
classes: 2
torch.Size([1, 3, 250, 250])
torch.Size([1, 250, 250, 3])
INFO: Starting training:
        Epochs:          5
        Batch size:      1
        Learning rate:   1e-05
        Training size:   1305
        Validation size: 145
        Checkpoints:     True
        Device:          cuda
        Images size:     [250.0, 250.0]
        Mixed Precision: True
Epoch 1/5:   0%|                                                                     | 0/1305 [00:00<?, ?img/s]
Traceback (most recent call last):
  File "train.py", line 194, in <module>
    amp=args.amp)
  File "train.py", line 96, in train_net
    loss = criterion(masks_pred, true_masks) \
  File "/home/nicolas/anaconda3/envs/josue_torch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/nicolas/anaconda3/envs/josue_torch/lib/python3.7/site-packages/torch/nn/modules/loss.py", line 1152, in forward
    label_smoothing=self.label_smoothing)
  File "/home/nicolas/anaconda3/envs/josue_torch/lib/python3.7/site-packages/torch/nn/functional.py", line 2846, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: only batches of spatial targets supported (3D tensors) but got targets of size: : [1, 250, 250, 3]